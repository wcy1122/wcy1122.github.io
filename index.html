
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Template from Han Guo */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 35px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="logo.jpg">
  <title>Chengyao Wang</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <script src="./utils.js"></script>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Chengyao Wang (王程钥)</name>
              </p>
              <p>
                I am a PhD student at the Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK), advised by Prof. <a href="https://jiaya.me/"> Jiaya Jia </a> and Prof. <a href="https://www.cse.cuhk.edu.hk/~byu/"> Bei Yu </a>. 
                Prior to that, I obtained my B.E. degree in Computer Science from Sun Yat-Sen University (SYSU).
                <br>
                <br>
                I am particular interested in building <span style="color: #ff0000;"><b>Human-like Multimodal Intelligence</b></span> that can actively interact to the physical world and have long-term memory.
                Recently, my research mainly focus on Multi-modal Large Language Models (MLLMs).
                Prior to that, I also had some experience on visual perception.
                <br>
                <br>
                I am actively seeking <span style="color: #ff0000;"><b>Industrial Opportunities for 2026 Fall</b></span> in any location. Fell free to contact if you are intersted.
                Research discussion and collaboration are always welcome, feel free to contact.
              </p>
              <p align=center>
                <a href="https://scholar.google.com/citations?user=1pZcoqgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/wcy1122"> GitHub </a> &nbsp/&nbsp
                <a href="https://twitter.com/wcy1122"> Twitter </a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/chengyao-wang-7487211a1/"> Linkdin </a> &nbsp/&nbsp
                <a href="mailto: wcy1122@link.cuhk.edu.hk"> Email </a>
              </p>
            </td>
            <td width="28%">
              <img src="selfie.png" style="width: 80%;">
            </td>
          </tr>
        </table>

        <!-- News -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="60%" valign="middle">
              <heading>News</heading>
              <ul>
                <li> <b>[2025-08]</b> We release <a href="https://mgm-omni.notion.site/MGM-Omni-An-Open-source-Omni-Chatbot-2395728e0b0180149ac9f24683fc9907"> MGM-Omni </a>, an open source omni moded support long speech understanding, generation and zero-shot voice clone. </li>
                <li> <b>[2025-06]</b> <a href="https://arxiv.org/abs/2412.09501"> Lyra </a> is accepted in ICCV 2025, Hawaii. </li>
                <li> <b>[2025-03]</b> <a href="https://arxiv.org/abs/2412.04467"> VisionZip </a> and <a href="https://arxiv.org/abs/2412.17098"> DreamOmni </a> are accepted in CVPR 2025, Nashville. </li>
                <li> <b>[2024-12]</b> We release <a href="https://arxiv.org/abs/2412.09501"> Lyra </a>, an open source multi-modal large language models that support long-speech comprehension, sound understanding, cross-modality efficiency, and seamless speech interaction. </li>
                <li> <b>[2024-07]</b> <a href="https://arxiv.org/abs/2311.17043"> LLaMA-VID </a> is accepted in ECCV 2024, Milano. </li>
                <li> <b>[2024-03]</b> We release <a href="https://arxiv.org/abs/2403.18814"> Mini-Gemini </a>, an open source vision-language models that support high-resolution image understanding, reasoning and generation. </li>
                <li> <b>[2024-02]</b> <a href="https://arxiv.org/abs/2403.09639"> GroupContrast </a> is accepted in CVPR 2024, Seattle. </li>
                <li> <b>[2023-11]</b> We release <a href="https://arxiv.org/abs/2311.17043"> LLaMA-VID </a>, an open source vision-language models that support hour-long video understanding and reasoning. </li>
              </ul>
            </td>
          </tr>
        </table>

        <!-- Researches -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research </heading>
              <p>
              * indicates equal contribution
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <!-- Projects -->
          
          <tr>
            <td width="25%" id="mgm-omni-img"></td>
            <td valign="top" width="75%" id="mgm-omni-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "mgm-omni", {
              title: "MGM-Omni: An Open-Source Omni Chatbot",
              paper_url: "https://mgm-omni.notion.site/MGM-Omni-An-Open-source-Omni-Chatbot-2395728e0b0180149ac9f24683fc9907",
              authors: "<b> Chengyao Wang* </b>, Zhisheng Zhong*, Bohao Peng*, Senqiao Yang, Yuqi Liu, Bei Yu, Jiaya Jia",
              conference: "Blog Post",
              image: "figures/MGM-Omni.jpg",
              others: "[<a href=\"https://mgm-omni.notion.site/MGM-Omni-An-Open-source-Omni-Chatbot-2395728e0b0180149ac9f24683fc9907\"><b>blog</b></a>] [<a href=\"https://github.com/dvlab-research/MGM-Omni\"><b>code</b></a>] [<a href=\"https://huggingface.co/spaces/wcy1122/MGM-Omni\"><b>demo</b></a>]"
            });
          </script>

          <tr>
            <td width="25%" id="lyra-img"></td>
            <td valign="top" width="75%" id="lyra-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "lyra", {
              title: "Lyra: An Efficient and Speech-Centric Framework for Omni-Cognition",
              paper_url: "https://arxiv.org/abs/2412.09501",
              authors: "Zhisheng Zhong*, <b> Chengyao Wang* </b>, Yuqi Liu*, Senqiao Yang, Longxiang Tang, Yuechen Zhang, Jingyao Li, Tianyuan Qu, Yanwei Li, Yukang Chen, Shaozuo Yu, Sitong Wu, Eric Lo, Shu Liu, Jiaya Jia",
              conference: "ICCV 2025",
              image: "figures/Lyra.png",
              others: "[<a href=\"https://arxiv.org/pdf/2412.09501.pdf\"><b>paper</b></a>] [<a href=\"https://github.com/dvlab-research/Lyra\"><b>code</b></a>] [<a href=\"https://lyra-omni.github.io/\"><b>project</b></a>] [<a href=\"https://103.170.5.190:17860/\"><b>demo</b></a>]"
            });
          </script>

          <tr>
            <td width="25%" id="visionzip-img"></td>
            <td valign="top" width="75%" id="visionzip-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "visionzip", {
              title: "VisionZip: Longer is Better but Not Necessary in Vision Language Models",
              paper_url: "https://arxiv.org/abs/2412.04467",
              authors: "Senqiao Yang, Yukang Chen, Zhuotao Tian, <b> Chengyao Wang </b>, Jingyao Li, Bei Yu, Jiaya Jia",
              conference: "CVPR 2025",
              image: "figures/VisionZip.png",
              others: "[<a href=\"https://arxiv.org/pdf/2412.04467.pdf\"><b>paper</b></a>] [<a href=\"https://github.com/dvlab-research/VisionZip\"><b>code</b></a>] [<a href=\"http://202.104.135.156:7860/\"><b>demo</b></a>]"
            });
          </script>

          <tr>
            <td width="25%" id="dreamomni-img"></td>
            <td valign="top" width="75%" id="dreamomni-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "dreamomni", {
              title: "DreamOmni: Unified Image Generation and Editing",
              paper_url: "https://arxiv.org/abs/2412.17098",
              authors: "Bin Xia, Yuechen Zhang, Jingyao Li, <b> Chengyao Wang </b>, Yitong Wang, Xinglong Wu, Bei Yu, Jiaya Jia",
              conference: "CVPR 2025",
              image: "figures/DreamOmni.png",
              others: "[<a href=\"https://arxiv.org/pdf/2412.17098.pdf\"><b>paper</b></a>] [<a href=\"https://zj-binxia.github.io/DreamOmni-ProjectPage\"><b>project</b></a>]"
            });
          </script>
          
          <tr>
            <td width="25%" id="minigemini-img"></td>
            <td valign="top" width="75%" id="minigemini-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "minigemini", {
              title: "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models",
              paper_url: "https://arxiv.org/abs/2403.18814",
              authors: "Yanwei Li*, Yuechen Zhang*, <b> Chengyao Wang* </b>, Zhisheng Zhong, Yixin Chen, Ruihang Chu, Shaoteng Liu, Jiaya Jia,",
              conference: "Preprint",
              image: "figures/MiniGemini.png",
              others: "[<a href=\"https://arxiv.org/pdf/2403.18814.pdf\"><b>paper</b></a>] [<a href=\"https://github.com/dvlab-research/MiniGemini\"><b>code</b></a>] [<a href=\"https://mini-gemini.github.io/\"><b>project</b></a>] [<a href=\"http://103.170.5.190:7860/\"><b>demo</b></a>]"
            });
          </script>

          <tr>
            <td width="25%" id="llamavid-img"></td>
            <td valign="top" width="75%" id="llamavid-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "llamavid", {
              title: "LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models",
              paper_url: "https://arxiv.org/abs/2311.17043",
              authors: "Yanwei Li*, <b> Chengyao Wang* </b>, Jiaya Jia",
              conference: "ECCV 2024",
              image: "figures/LLaMA-VID.png",
              others: "[<a href=\"https://arxiv.org/pdf/2311.17043.pdf\"><b>paper</b></a>] [<a href=\"https://github.com/dvlab-research/LLaMA-VID\"><b>code</b></a>] [<a href=\"https://llama-vid.github.io/\"><b>project</b></a>] [<a href=\"http://103.170.5.190:7864/\"><b>demo</b></a>]"
            });
          </script>

          <tr>
            <td width="25%" id="groupcontrast-img"></td>
            <td valign="top" width="75%" id="groupcontrast-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "groupcontrast", {
              title: "GroupContrast: Semantic-aware Self-supervised Representation Learning for 3D Understanding",
              paper_url: "https://arxiv.org/abs/2403.09639",
              authors: "<b> Chengyao Wang </b>, Li Jiang, Xiaoyang Wu, Zhuotao Tian, Bohao Peng, Hengshuang Zhao, Jiaya Jia",
              conference: "CVPR 2024",
              image: "figures/GroupContrast.png",
              others: "[<a href=\"https://arxiv.org/pdf/2403.09639.pdf\"><b>paper</b></a>] [<a href=\"https://github.com/dvlab-research/GroupContrast\"><b>code</b></a>]"
            });
          </script>

          <tr>
            <td width="25%" id="hdmnet-img"></td>
            <td valign="top" width="75%" id="hdmnet-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "hdmnet", {
              title: "Hierarchical Dense Correlation Distillation for Few-Shot Segmentation",
              paper_url: "https://arxiv.org/abs/2303.14652",
              authors: "Bohao Peng, Zhuotao Tian, Xiaoyang Wu, <b> Chengyao Wang </b>, Shu Liu, Jingyong Su, Jiaya Jia",
              conference: "CVPR 2023 (Highlight)",
              image: "figures/HDMNet.png",
              others: "[<a href=\"https://arxiv.org/pdf/2303.14652.pdf\"><b>paper</b></a>] [<a href=\"https://github.com/Pbihao/HDMNet\"><b>code</b></a>]"
            });
          </script>

          <tr>
            <td width="25%" id="msil-img"></td>
            <td valign="top" width="75%" id="msil-txt"></td>
          </tr>
          <script type="text/javascript">
            createProjectElement(
              id = "msil", {
              title: "Mixed supervision for instance learning in object detection with few-shot annotation",
              paper_url: "https://dl.acm.org/doi/abs/10.1145/3503161.3548242",
              authors: "Yi Zhong*, <b> Chengyao Wang* </b>, Shiyong Li, Zhu Zhou, Yaowei Wang, Wei-Shi Zheng",
              conference: "ACM MM 2022",
              image: "figures/MSIL.png",
              others: "[<a href=\"https://drive.google.com/file/d/1AGChiG00dIMrvqPhtChj26uE_Etz3Vxj/view\"><b>paper</b></a>]"
            });
          </script>

        </tabel>

        <!-- Awards -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="60%" valign="middle">
              <heading>Selected Awards</heading>
              <ul>
                <li> Gold Medal x 3, <b>International Collegiate Programming Contest (ICPC), Regional</b> </li>
                <li> Gold Medal, <b>Chinese Collegiate Programming Contest (CCPC)</b> </li>
              </ul>
            </td>
          </tr>
        </table>

        <!-- Academic Service -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="60%" valign="middle">
              <heading>Academic Service</heading>
              <p>
                <b>Reviewer / Program Committee Member</b>
              </p>
              <ul>
                <li> IEEE International Conference on Computer Vision (ICCV) </li>
                <li> Conference on Neural Information Processing Systems (NeurIPS) </li>
                <li> Association for the Advancement of Artificial Intelligence (AAAI) </li>
                <li> IEEE Winter Conference on Applications of Computer Vision (WACV) </li>
              </ul>
            </td>
          </tr>
        </table>

        <table
          style="width:50%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:30%;vertical-align:middle">
                <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=HwqhcZKNc3n2Az2F-fAc4sG-jBpdLe8XOiMForJ2a9M'></script>
              </td>
            </tr>
          </tbody>
        </table>

      </td>
    </tr>
  </tabel>
</body>

</html>
